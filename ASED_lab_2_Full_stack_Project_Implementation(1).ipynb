{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y8nSv_cEXc1H"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn import linear_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "height=[[4.0],[5.0],[6.0],[7.0],[8.0],[9.0],[10.0]]\n",
        "weight=[  8, 10 , 12, 14, 16, 18, 20]\n",
        "plt.scatter(height,weight,color='black')\n",
        "plt.xlabel(\"height\")\n",
        "plt.ylabel(\"weight\")\n",
        "reg=linear_model.LinearRegression()\n",
        "reg.fit(height,weight)\n",
        "X_height=[[12.0]]\n",
        "print(reg.predict(X_height))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "m_gEEvkxX_93",
        "outputId": "df4863d7-f485-44cd-acdd-05ccb3a4e885"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[24.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(reg.predict([[11.0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb-fwsiVagXA",
        "outputId": "31fafb46-56d9-4270-892a-6b3d12b73cb0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import modules\n",
        "import warnings\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import linear_model\n",
        "X=[[4.0],[5.0],[6.0],[7.0],[8.0],[9.0],[10.0]]\n",
        "y=[  8, 10 , 12, 14, 16, 18, 20]\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=7)\n",
        "print(\"Training Features\", X_train);print(\"Training Labels\",y_train);print(\"Training Data\",X_test);print(\"Testing Data\",y_test)\n",
        "reg=linear_model.LinearRegression()\n",
        "reg.fit(X_train,y_train)\n",
        "#accuracy on test set\n",
        "result = reg.score(X_test, y_test)\n",
        "print(\"Accuracy - test set: %.2f%%\" % (result*100.0))\n",
        "X_height=[[12.0]]\n",
        "print(reg.predict(X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Egz49GFRYE3U",
        "outputId": "6459c041-c8e0-4ae0-b817-4edd093607e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features [[10.0], [7.0], [5.0], [8.0]]\n",
            "Training Labels [20, 14, 10, 16]\n",
            "Training Data [[6.0], [9.0], [4.0]]\n",
            "Testing Data [12, 18, 8]\n",
            "Accuracy - test set: 100.00%\n",
            "[12. 18.  8.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "x=[[4.0],[5.0],[6.0],[7.0],[8.0],[9.0],[10.0]]\n",
        "y=[  16, 25 , 36, 49,64,81, 100]\n",
        "# Step 2 - Fitting Linear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(x,y)\n",
        "\n",
        "# Step 4 Linear Regression prediction\n",
        "print(lin_reg.predict([[11]]))\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "polynomial_regression = make_pipeline(\n",
        "    PolynomialFeatures(degree=1, include_bias=False),\n",
        "    LinearRegression(),\n",
        ")\n",
        "polynomial_regression.fit(x,y)\n",
        "X_height=[[20.0]]\n",
        "target_predicted = polynomial_regression.predict(X_height)\n",
        "print(target_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZBLn8HWYY3M",
        "outputId": "c54051a3-521a-43bd-b152-d88e19e34d75"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[109.]\n",
            "[235.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "x=[[4.0],[5.0],[6.0],[7.0],[8.0],[9.0],[10.0]]\n",
        "y=[  16, 25 , 36, 49,64,81, 100] # Changed y to x^2 values\n",
        "# Step 2 - Fitting Linear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(x,y)\n",
        "\n",
        "# Step 4 Linear Regression prediction\n",
        "print(lin_reg.predict([[11]]))\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "polynomial_regression = make_pipeline(\n",
        "    PolynomialFeatures(degree=2, include_bias=False), # Changed degree to 2\n",
        "    LinearRegression(),\n",
        ")\n",
        "polynomial_regression.fit(x,y)\n",
        "X_height=[[20.0]]\n",
        "target_predicted = polynomial_regression.predict(X_height)\n",
        "print(target_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lile2uO3Ym6T",
        "outputId": "83b59b90-1ab1-48e0-bf1b-f4ec8320797f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[109.]\n",
            "[400.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "x=[[4.0],[5.0],[6.0],[7.0],[8.0],[9.0],[10.0]]\n",
        "y=[  64, 125 , 36, 343,512,729, 1000]\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(x,y)\n",
        "\n",
        "print(lin_reg.predict([[11]]))\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "polynomial_regression = make_pipeline(\n",
        "    PolynomialFeatures(degree=3, include_bias=False),\n",
        "    LinearRegression(),\n",
        ")\n",
        "polynomial_regression.fit(x,y)\n",
        "X_height=[[20.0]]\n",
        "target_predicted = polynomial_regression.predict(X_height)\n",
        "print(target_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AEX7_gcYvfK",
        "outputId": "af87262e-e217-47a4-e02c-463d00436e56"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1043.]\n",
            "[-1411.42857143]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oau-NsIVb9K5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "x=[[4.0],[5.0],[6.0],[7.0],[8.0],[9.0],[10.0]]\n",
        "y=[  16, 25 , 36, 49,64,81, 100] # Changed y to x^2 values\n",
        "# Step 2 - Fitting Linear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(x,y)\n",
        "\n",
        "# Step 4 Linear Regression prediction\n",
        "print(lin_reg.predict([[11]]))\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "polynomial_regression = make_pipeline(\n",
        "    PolynomialFeatures(degree=3, include_bias=False), # Changed degree to 2\n",
        "    LinearRegression(),\n",
        ")\n",
        "polynomial_regression.fit(x,y)\n",
        "X_height=[[20.0]]\n",
        "target_predicted = polynomial_regression.predict(X_height)\n",
        "print(target_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16620d3-ce2d-4d9e-f169-a8f797df4e6e",
        "id": "Hb4kIY3bduJO"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[109.]\n",
            "[400.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer (10 features)\n",
        "model.add(Input(shape=(10,)))\n",
        "\n",
        "# 1st hidden layer\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# 2nd hidden layer\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "UNVEg7FqdvEh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Keras specific\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "x = np.array([[4],[5],[6],[7],[8],[9],[10]]) # Convert x to a NumPy array\n",
        "y = np.array([8, 10 , 12, 14, 16, 18, 20]) # Convert y to a NumPy array\n",
        "# Define model\n",
        "model = Sequential()\n",
        "model.add(Dense(1000, input_dim=1, activation= \"relu\"))\n",
        "model.add(Dense(1000, activation= \"relu\"))\n",
        "model.add(Dense(50, activation= \"relu\"))\n",
        "model.add(Dense(1))\n",
        "#model.summary() #Print model Summarymodel.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
        "model.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
        "model.fit(x,y,epochs=300)\n",
        "x_predict = np.array([[12.0]]) # Convert the prediction input to a NumPy array\n",
        "print(model.predict(x_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTRKXnSngUq7",
        "outputId": "8b1233bf-afaf-4a02-9643-04bfcacbf056"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 207.6051 - mean_squared_error: 207.6051\n",
            "Epoch 2/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 154.4352 - mean_squared_error: 154.4352\n",
            "Epoch 3/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 112.8091 - mean_squared_error: 112.8091\n",
            "Epoch 4/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 76.5306 - mean_squared_error: 76.5306\n",
            "Epoch 5/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 44.6086 - mean_squared_error: 44.6086\n",
            "Epoch 6/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 19.2396 - mean_squared_error: 19.2396\n",
            "Epoch 7/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.5696 - mean_squared_error: 3.5696\n",
            "Epoch 8/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5206 - mean_squared_error: 0.5206\n",
            "Epoch 9/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 9.6816 - mean_squared_error: 9.6816\n",
            "Epoch 10/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 22.9307 - mean_squared_error: 22.9307\n",
            "Epoch 11/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 30.0407 - mean_squared_error: 30.0407\n",
            "Epoch 12/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 28.1836 - mean_squared_error: 28.1836\n",
            "Epoch 13/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 20.0152 - mean_squared_error: 20.0152\n",
            "Epoch 14/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 10.7196 - mean_squared_error: 10.7196\n",
            "Epoch 15/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.7065 - mean_squared_error: 3.7065\n",
            "Epoch 16/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3571 - mean_squared_error: 0.3571\n",
            "Epoch 17/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3660 - mean_squared_error: 0.3660\n",
            "Epoch 18/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.4925 - mean_squared_error: 2.4925\n",
            "Epoch 19/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.2862 - mean_squared_error: 5.2862\n",
            "Epoch 20/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 7.6077 - mean_squared_error: 7.6077\n",
            "Epoch 21/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 8.8425 - mean_squared_error: 8.8425\n",
            "Epoch 22/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 8.8033 - mean_squared_error: 8.8033\n",
            "Epoch 23/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 7.6689 - mean_squared_error: 7.6689\n",
            "Epoch 24/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.8136 - mean_squared_error: 5.8136\n",
            "Epoch 25/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 3.6876 - mean_squared_error: 3.6876\n",
            "Epoch 26/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7810 - mean_squared_error: 1.7810\n",
            "Epoch 27/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4795 - mean_squared_error: 0.4795\n",
            "Epoch 28/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
            "Epoch 29/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3291 - mean_squared_error: 0.3291\n",
            "Epoch 30/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.1755 - mean_squared_error: 1.1755\n",
            "Epoch 31/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.0999 - mean_squared_error: 2.0999\n",
            "Epoch 32/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.6892 - mean_squared_error: 2.6892\n",
            "Epoch 33/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.7267 - mean_squared_error: 2.7267\n",
            "Epoch 34/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.2482 - mean_squared_error: 2.2482\n",
            "Epoch 35/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.4791 - mean_squared_error: 1.4791\n",
            "Epoch 36/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.7152 - mean_squared_error: 0.7152\n",
            "Epoch 37/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1884 - mean_squared_error: 0.1884\n",
            "Epoch 38/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
            "Epoch 39/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1234 - mean_squared_error: 0.1234\n",
            "Epoch 40/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4218 - mean_squared_error: 0.4218\n",
            "Epoch 41/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.7331 - mean_squared_error: 0.7331\n",
            "Epoch 42/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.9302 - mean_squared_error: 0.9302\n",
            "Epoch 43/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.9533 - mean_squared_error: 0.9533\n",
            "Epoch 44/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.8120 - mean_squared_error: 0.8120\n",
            "Epoch 45/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5671 - mean_squared_error: 0.5671\n",
            "Epoch 46/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3035 - mean_squared_error: 0.3035\n",
            "Epoch 47/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.1003 - mean_squared_error: 0.1003\n",
            "Epoch 48/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
            "Epoch 49/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0268 - mean_squared_error: 0.0268\n",
            "Epoch 50/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.1266 - mean_squared_error: 0.1266\n",
            "Epoch 51/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.2465 - mean_squared_error: 0.2465\n",
            "Epoch 52/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3289 - mean_squared_error: 0.3289\n",
            "Epoch 53/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3402 - mean_squared_error: 0.3402\n",
            "Epoch 54/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.2816 - mean_squared_error: 0.2816\n",
            "Epoch 55/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.1824 - mean_squared_error: 0.1824\n",
            "Epoch 56/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0835 - mean_squared_error: 0.0835\n",
            "Epoch 57/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0184 - mean_squared_error: 0.0184\n",
            "Epoch 58/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
            "Epoch 59/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0265 - mean_squared_error: 0.0265\n",
            "Epoch 60/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0719 - mean_squared_error: 0.0719\n",
            "Epoch 61/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.1130 - mean_squared_error: 0.1130\n",
            "Epoch 62/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.1319 - mean_squared_error: 0.1319\n",
            "Epoch 63/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.1222 - mean_squared_error: 0.1222\n",
            "Epoch 64/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0904 - mean_squared_error: 0.0904\n",
            "Epoch 65/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0503 - mean_squared_error: 0.0503\n",
            "Epoch 66/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0174 - mean_squared_error: 0.0174\n",
            "Epoch 67/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
            "Epoch 68/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
            "Epoch 69/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0218 - mean_squared_error: 0.0218\n",
            "Epoch 70/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0404 - mean_squared_error: 0.0404\n",
            "Epoch 71/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0514 - mean_squared_error: 0.0514\n",
            "Epoch 72/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0501 - mean_squared_error: 0.0501\n",
            "Epoch 73/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0382 - mean_squared_error: 0.0382\n",
            "Epoch 74/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0218 - mean_squared_error: 0.0218\n",
            "Epoch 75/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0079 - mean_squared_error: 0.0079\n",
            "Epoch 76/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 77/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
            "Epoch 78/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
            "Epoch 79/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0174 - mean_squared_error: 0.0174\n",
            "Epoch 80/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0215 - mean_squared_error: 0.0215\n",
            "Epoch 81/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0205 - mean_squared_error: 0.0205\n",
            "Epoch 82/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0153 - mean_squared_error: 0.0153\n",
            "Epoch 83/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
            "Epoch 84/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
            "Epoch 85/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
            "Epoch 86/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
            "Epoch 87/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
            "Epoch 88/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
            "Epoch 89/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0095 - mean_squared_error: 0.0095\n",
            "Epoch 90/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
            "Epoch 91/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
            "Epoch 92/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
            "Epoch 93/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
            "Epoch 94/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 95/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
            "Epoch 96/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
            "Epoch 97/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
            "Epoch 98/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
            "Epoch 99/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
            "Epoch 100/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
            "Epoch 101/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 102/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 9.3462e-04 - mean_squared_error: 9.3462e-04\n",
            "Epoch 103/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 104/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
            "Epoch 105/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
            "Epoch 106/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
            "Epoch 107/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
            "Epoch 108/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
            "Epoch 109/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 110/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 8.9550e-04 - mean_squared_error: 8.9550e-04\n",
            "Epoch 111/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 9.9960e-04 - mean_squared_error: 9.9960e-04\n",
            "Epoch 112/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
            "Epoch 113/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
            "Epoch 114/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
            "Epoch 115/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 116/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 117/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 9.4541e-04 - mean_squared_error: 9.4541e-04\n",
            "Epoch 118/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 8.5609e-04 - mean_squared_error: 8.5609e-04\n",
            "Epoch 119/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 9.0099e-04 - mean_squared_error: 9.0099e-04\n",
            "Epoch 120/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
            "Epoch 121/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 122/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 123/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 124/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 9.4379e-04 - mean_squared_error: 9.4379e-04\n",
            "Epoch 125/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 8.5075e-04 - mean_squared_error: 8.5075e-04\n",
            "Epoch 126/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 8.1736e-04 - mean_squared_error: 8.1736e-04\n",
            "Epoch 127/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 8.4303e-04 - mean_squared_error: 8.4303e-04\n",
            "Epoch 128/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 8.9441e-04 - mean_squared_error: 8.9441e-04\n",
            "Epoch 129/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 9.3000e-04 - mean_squared_error: 9.3000e-04\n",
            "Epoch 130/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 9.2529e-04 - mean_squared_error: 9.2529e-04\n",
            "Epoch 131/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 8.8364e-04 - mean_squared_error: 8.8364e-04\n",
            "Epoch 132/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 8.2944e-04 - mean_squared_error: 8.2944e-04\n",
            "Epoch 133/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 7.9052e-04 - mean_squared_error: 7.9052e-04\n",
            "Epoch 134/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 7.8105e-04 - mean_squared_error: 7.8105e-04\n",
            "Epoch 135/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 7.9584e-04 - mean_squared_error: 7.9584e-04\n",
            "Epoch 136/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 8.1658e-04 - mean_squared_error: 8.1658e-04\n",
            "Epoch 137/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 8.2507e-04 - mean_squared_error: 8.2507e-04\n",
            "Epoch 138/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8.1382e-04 - mean_squared_error: 8.1382e-04\n",
            "Epoch 139/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 7.8852e-04 - mean_squared_error: 7.8852e-04\n",
            "Epoch 140/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 7.6241e-04 - mean_squared_error: 7.6241e-04\n",
            "Epoch 141/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 7.4706e-04 - mean_squared_error: 7.4706e-04\n",
            "Epoch 142/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 7.4553e-04 - mean_squared_error: 7.4553e-04\n",
            "Epoch 143/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 7.5229e-04 - mean_squared_error: 7.5229e-04\n",
            "Epoch 144/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 7.5786e-04 - mean_squared_error: 7.5786e-04\n",
            "Epoch 145/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 7.5535e-04 - mean_squared_error: 7.5535e-04\n",
            "Epoch 146/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 7.4395e-04 - mean_squared_error: 7.4395e-04\n",
            "Epoch 147/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 7.2881e-04 - mean_squared_error: 7.2881e-04\n",
            "Epoch 148/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 7.1625e-04 - mean_squared_error: 7.1625e-04\n",
            "Epoch 149/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 7.1012e-04 - mean_squared_error: 7.1012e-04\n",
            "Epoch 150/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 7.0956e-04 - mean_squared_error: 7.0956e-04\n",
            "Epoch 151/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 7.1064e-04 - mean_squared_error: 7.1064e-04\n",
            "Epoch 152/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 7.0903e-04 - mean_squared_error: 7.0903e-04\n",
            "Epoch 153/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 7.0303e-04 - mean_squared_error: 7.0303e-04\n",
            "Epoch 154/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 6.9394e-04 - mean_squared_error: 6.9394e-04\n",
            "Epoch 155/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 6.8488e-04 - mean_squared_error: 6.8488e-04\n",
            "Epoch 156/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 6.7844e-04 - mean_squared_error: 6.7844e-04\n",
            "Epoch 157/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 6.7505e-04 - mean_squared_error: 6.7505e-04\n",
            "Epoch 158/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 6.7327e-04 - mean_squared_error: 6.7327e-04\n",
            "Epoch 159/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 6.7085e-04 - mean_squared_error: 6.7085e-04\n",
            "Epoch 160/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.6646e-04 - mean_squared_error: 6.6646e-04\n",
            "Epoch 161/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.6024e-04 - mean_squared_error: 6.6024e-04\n",
            "Epoch 162/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 6.5347e-04 - mean_squared_error: 6.5347e-04\n",
            "Epoch 163/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 6.4777e-04 - mean_squared_error: 6.4777e-04\n",
            "Epoch 164/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 6.4358e-04 - mean_squared_error: 6.4358e-04\n",
            "Epoch 165/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 6.4036e-04 - mean_squared_error: 6.4036e-04\n",
            "Epoch 166/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 6.3717e-04 - mean_squared_error: 6.3717e-04\n",
            "Epoch 167/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.3312e-04 - mean_squared_error: 6.3312e-04\n",
            "Epoch 168/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 6.2815e-04 - mean_squared_error: 6.2815e-04\n",
            "Epoch 169/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.2274e-04 - mean_squared_error: 6.2274e-04\n",
            "Epoch 170/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 6.1767e-04 - mean_squared_error: 6.1767e-04\n",
            "Epoch 171/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 6.1339e-04 - mean_squared_error: 6.1339e-04\n",
            "Epoch 172/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 6.0963e-04 - mean_squared_error: 6.0963e-04\n",
            "Epoch 173/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 6.0602e-04 - mean_squared_error: 6.0602e-04\n",
            "Epoch 174/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 6.0206e-04 - mean_squared_error: 6.0206e-04\n",
            "Epoch 175/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 5.9757e-04 - mean_squared_error: 5.9757e-04\n",
            "Epoch 176/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 5.9288e-04 - mean_squared_error: 5.9288e-04\n",
            "Epoch 177/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 5.8830e-04 - mean_squared_error: 5.8830e-04\n",
            "Epoch 178/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.8412e-04 - mean_squared_error: 5.8412e-04\n",
            "Epoch 179/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 5.8017e-04 - mean_squared_error: 5.8017e-04\n",
            "Epoch 180/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.7638e-04 - mean_squared_error: 5.7638e-04\n",
            "Epoch 181/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.7241e-04 - mean_squared_error: 5.7241e-04\n",
            "Epoch 182/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.6824e-04 - mean_squared_error: 5.6824e-04\n",
            "Epoch 183/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.6391e-04 - mean_squared_error: 5.6391e-04\n",
            "Epoch 184/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.5969e-04 - mean_squared_error: 5.5969e-04\n",
            "Epoch 185/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.5560e-04 - mean_squared_error: 5.5560e-04\n",
            "Epoch 186/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 5.5172e-04 - mean_squared_error: 5.5172e-04\n",
            "Epoch 187/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.4787e-04 - mean_squared_error: 5.4787e-04\n",
            "Epoch 188/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 5.4394e-04 - mean_squared_error: 5.4394e-04\n",
            "Epoch 189/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.3995e-04 - mean_squared_error: 5.3995e-04\n",
            "Epoch 190/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.3588e-04 - mean_squared_error: 5.3588e-04\n",
            "Epoch 191/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.3186e-04 - mean_squared_error: 5.3186e-04\n",
            "Epoch 192/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.2793e-04 - mean_squared_error: 5.2793e-04\n",
            "Epoch 193/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.2409e-04 - mean_squared_error: 5.2409e-04\n",
            "Epoch 194/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.2028e-04 - mean_squared_error: 5.2028e-04\n",
            "Epoch 195/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.1648e-04 - mean_squared_error: 5.1648e-04\n",
            "Epoch 196/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.1258e-04 - mean_squared_error: 5.1258e-04\n",
            "Epoch 197/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.0871e-04 - mean_squared_error: 5.0871e-04\n",
            "Epoch 198/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 5.0489e-04 - mean_squared_error: 5.0489e-04\n",
            "Epoch 199/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.0110e-04 - mean_squared_error: 5.0110e-04\n",
            "Epoch 200/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 4.9733e-04 - mean_squared_error: 4.9733e-04\n",
            "Epoch 201/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 4.9364e-04 - mean_squared_error: 4.9364e-04\n",
            "Epoch 202/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 4.8989e-04 - mean_squared_error: 4.8989e-04\n",
            "Epoch 203/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 4.8620e-04 - mean_squared_error: 4.8620e-04\n",
            "Epoch 204/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 4.8242e-04 - mean_squared_error: 4.8242e-04\n",
            "Epoch 205/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 4.7875e-04 - mean_squared_error: 4.7875e-04\n",
            "Epoch 206/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 4.7509e-04 - mean_squared_error: 4.7509e-04\n",
            "Epoch 207/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 4.7146e-04 - mean_squared_error: 4.7146e-04\n",
            "Epoch 208/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 4.6782e-04 - mean_squared_error: 4.6782e-04\n",
            "Epoch 209/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 4.6423e-04 - mean_squared_error: 4.6423e-04\n",
            "Epoch 210/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 4.6062e-04 - mean_squared_error: 4.6062e-04\n",
            "Epoch 211/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 4.5706e-04 - mean_squared_error: 4.5706e-04\n",
            "Epoch 212/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 4.5345e-04 - mean_squared_error: 4.5345e-04\n",
            "Epoch 213/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 4.4994e-04 - mean_squared_error: 4.4994e-04\n",
            "Epoch 214/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 4.4641e-04 - mean_squared_error: 4.4641e-04\n",
            "Epoch 215/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 4.4294e-04 - mean_squared_error: 4.4294e-04\n",
            "Epoch 216/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 4.3943e-04 - mean_squared_error: 4.3943e-04\n",
            "Epoch 217/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 4.3595e-04 - mean_squared_error: 4.3595e-04\n",
            "Epoch 218/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 4.3252e-04 - mean_squared_error: 4.3252e-04\n",
            "Epoch 219/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 4.2907e-04 - mean_squared_error: 4.2907e-04\n",
            "Epoch 220/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 4.2567e-04 - mean_squared_error: 4.2567e-04\n",
            "Epoch 221/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 4.2229e-04 - mean_squared_error: 4.2229e-04\n",
            "Epoch 222/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 4.1890e-04 - mean_squared_error: 4.1890e-04\n",
            "Epoch 223/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 4.1554e-04 - mean_squared_error: 4.1554e-04\n",
            "Epoch 224/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 4.1219e-04 - mean_squared_error: 4.1219e-04\n",
            "Epoch 225/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 4.0888e-04 - mean_squared_error: 4.0888e-04\n",
            "Epoch 226/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 4.0554e-04 - mean_squared_error: 4.0554e-04\n",
            "Epoch 227/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 4.0228e-04 - mean_squared_error: 4.0228e-04\n",
            "Epoch 228/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.9901e-04 - mean_squared_error: 3.9901e-04\n",
            "Epoch 229/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.9573e-04 - mean_squared_error: 3.9573e-04\n",
            "Epoch 230/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 3.9253e-04 - mean_squared_error: 3.9253e-04\n",
            "Epoch 231/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 3.8931e-04 - mean_squared_error: 3.8931e-04\n",
            "Epoch 232/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 3.8613e-04 - mean_squared_error: 3.8613e-04\n",
            "Epoch 233/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 3.8293e-04 - mean_squared_error: 3.8293e-04\n",
            "Epoch 234/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 3.7977e-04 - mean_squared_error: 3.7977e-04\n",
            "Epoch 235/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 3.7666e-04 - mean_squared_error: 3.7666e-04\n",
            "Epoch 236/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.7352e-04 - mean_squared_error: 3.7352e-04\n",
            "Epoch 237/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 3.7039e-04 - mean_squared_error: 3.7039e-04\n",
            "Epoch 238/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 3.6733e-04 - mean_squared_error: 3.6733e-04\n",
            "Epoch 239/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.6424e-04 - mean_squared_error: 3.6424e-04\n",
            "Epoch 240/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.6119e-04 - mean_squared_error: 3.6119e-04\n",
            "Epoch 241/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 3.5816e-04 - mean_squared_error: 3.5816e-04\n",
            "Epoch 242/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 3.5515e-04 - mean_squared_error: 3.5515e-04\n",
            "Epoch 243/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 3.5214e-04 - mean_squared_error: 3.5214e-04\n",
            "Epoch 244/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 3.4918e-04 - mean_squared_error: 3.4918e-04\n",
            "Epoch 245/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 3.4621e-04 - mean_squared_error: 3.4621e-04\n",
            "Epoch 246/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 3.4326e-04 - mean_squared_error: 3.4326e-04\n",
            "Epoch 247/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 3.4031e-04 - mean_squared_error: 3.4031e-04\n",
            "Epoch 248/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.3741e-04 - mean_squared_error: 3.3741e-04\n",
            "Epoch 249/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 3.3453e-04 - mean_squared_error: 3.3453e-04\n",
            "Epoch 250/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 3.3164e-04 - mean_squared_error: 3.3164e-04\n",
            "Epoch 251/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 3.2880e-04 - mean_squared_error: 3.2880e-04\n",
            "Epoch 252/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 3.2598e-04 - mean_squared_error: 3.2598e-04\n",
            "Epoch 253/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 3.2315e-04 - mean_squared_error: 3.2315e-04\n",
            "Epoch 254/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3.2032e-04 - mean_squared_error: 3.2032e-04\n",
            "Epoch 255/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 3.1754e-04 - mean_squared_error: 3.1754e-04\n",
            "Epoch 256/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 3.1478e-04 - mean_squared_error: 3.1478e-04\n",
            "Epoch 257/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 3.1206e-04 - mean_squared_error: 3.1206e-04\n",
            "Epoch 258/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 3.0929e-04 - mean_squared_error: 3.0929e-04\n",
            "Epoch 259/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 3.0657e-04 - mean_squared_error: 3.0657e-04\n",
            "Epoch 260/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 3.0389e-04 - mean_squared_error: 3.0389e-04\n",
            "Epoch 261/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 3.0121e-04 - mean_squared_error: 3.0121e-04\n",
            "Epoch 262/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 2.9856e-04 - mean_squared_error: 2.9856e-04\n",
            "Epoch 263/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 2.9588e-04 - mean_squared_error: 2.9588e-04\n",
            "Epoch 264/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.9329e-04 - mean_squared_error: 2.9329e-04\n",
            "Epoch 265/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 2.9066e-04 - mean_squared_error: 2.9066e-04\n",
            "Epoch 266/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 2.8807e-04 - mean_squared_error: 2.8807e-04\n",
            "Epoch 267/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 2.8551e-04 - mean_squared_error: 2.8551e-04\n",
            "Epoch 268/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2.8294e-04 - mean_squared_error: 2.8294e-04\n",
            "Epoch 269/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 2.8039e-04 - mean_squared_error: 2.8039e-04\n",
            "Epoch 270/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.7787e-04 - mean_squared_error: 2.7787e-04\n",
            "Epoch 271/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 2.7534e-04 - mean_squared_error: 2.7534e-04\n",
            "Epoch 272/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 2.7287e-04 - mean_squared_error: 2.7287e-04\n",
            "Epoch 273/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.7042e-04 - mean_squared_error: 2.7042e-04\n",
            "Epoch 274/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.6796e-04 - mean_squared_error: 2.6796e-04\n",
            "Epoch 275/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 2.6551e-04 - mean_squared_error: 2.6551e-04\n",
            "Epoch 276/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.6309e-04 - mean_squared_error: 2.6309e-04\n",
            "Epoch 277/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 2.6069e-04 - mean_squared_error: 2.6069e-04\n",
            "Epoch 278/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2.5831e-04 - mean_squared_error: 2.5831e-04\n",
            "Epoch 279/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 2.5591e-04 - mean_squared_error: 2.5591e-04\n",
            "Epoch 280/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.5356e-04 - mean_squared_error: 2.5356e-04\n",
            "Epoch 281/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.5123e-04 - mean_squared_error: 2.5123e-04\n",
            "Epoch 282/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2.4890e-04 - mean_squared_error: 2.4890e-04\n",
            "Epoch 283/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 2.4660e-04 - mean_squared_error: 2.4660e-04\n",
            "Epoch 284/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 2.4431e-04 - mean_squared_error: 2.4431e-04\n",
            "Epoch 285/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 2.4204e-04 - mean_squared_error: 2.4204e-04\n",
            "Epoch 286/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 2.3978e-04 - mean_squared_error: 2.3978e-04\n",
            "Epoch 287/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 2.3754e-04 - mean_squared_error: 2.3754e-04\n",
            "Epoch 288/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.3533e-04 - mean_squared_error: 2.3533e-04\n",
            "Epoch 289/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 2.3310e-04 - mean_squared_error: 2.3310e-04\n",
            "Epoch 290/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 2.3091e-04 - mean_squared_error: 2.3091e-04\n",
            "Epoch 291/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 2.2874e-04 - mean_squared_error: 2.2874e-04\n",
            "Epoch 292/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.2658e-04 - mean_squared_error: 2.2658e-04\n",
            "Epoch 293/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.2442e-04 - mean_squared_error: 2.2442e-04\n",
            "Epoch 294/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2.2231e-04 - mean_squared_error: 2.2231e-04\n",
            "Epoch 295/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 2.2018e-04 - mean_squared_error: 2.2018e-04\n",
            "Epoch 296/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.1812e-04 - mean_squared_error: 2.1812e-04\n",
            "Epoch 297/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 2.1603e-04 - mean_squared_error: 2.1603e-04\n",
            "Epoch 298/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 2.1396e-04 - mean_squared_error: 2.1396e-04\n",
            "Epoch 299/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 2.1191e-04 - mean_squared_error: 2.1191e-04\n",
            "Epoch 300/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 2.0988e-04 - mean_squared_error: 2.0988e-04\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step\n",
            "[[23.96921]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "dHL-TfqgguS3",
        "outputId": "c1ea57cb-9896-45be-92d3-99f986ba2e57"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Trainer.compile of <Sequential name=sequential_1, built=True>>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>keras.src.trainers.trainer.Trainer.compile</b><br/>def compile(optimizer=&#x27;rmsprop&#x27;, loss=None, loss_weights=None, metrics=None, weighted_metrics=None, run_eagerly=False, steps_per_execution=1, jit_compile=&#x27;auto&#x27;, auto_scale_loss=True)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/keras/src/trainers/trainer.py</a>Configures the model for training.\n",
              "\n",
              "Example:\n",
              "\n",
              "```python\n",
              "model.compile(\n",
              "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
              "    loss=keras.losses.BinaryCrossentropy(),\n",
              "    metrics=[\n",
              "        keras.metrics.BinaryAccuracy(),\n",
              "        keras.metrics.FalseNegatives(),\n",
              "    ],\n",
              ")\n",
              "```\n",
              "\n",
              "Args:\n",
              "    optimizer: String (name of optimizer) or optimizer instance. See\n",
              "        `keras.optimizers`.\n",
              "    loss: Loss function. May be a string (name of loss function), or\n",
              "        a `keras.losses.Loss` instance. See `keras.losses`. A\n",
              "        loss function is any callable with the signature\n",
              "        `loss = fn(y_true, y_pred)`, where `y_true` are the ground truth\n",
              "        values, and `y_pred` are the model&#x27;s predictions.\n",
              "        `y_true` should have shape `(batch_size, d0, .. dN)`\n",
              "        (except in the case of sparse loss functions such as\n",
              "        sparse categorical crossentropy which expects integer arrays of\n",
              "        shape `(batch_size, d0, .. dN-1)`).\n",
              "        `y_pred` should have shape `(batch_size, d0, .. dN)`.\n",
              "        The loss function should return a float tensor.\n",
              "    loss_weights: Optional list or dictionary specifying scalar\n",
              "        coefficients (Python floats) to weight the loss contributions of\n",
              "        different model outputs. The loss value that will be minimized\n",
              "        by the model will then be the *weighted sum* of all individual\n",
              "        losses, weighted by the `loss_weights` coefficients.  If a list,\n",
              "        it is expected to have a 1:1 mapping to the model&#x27;s outputs. If\n",
              "        a dict, it is expected to map output names (strings) to scalar\n",
              "        coefficients.\n",
              "    metrics: List of metrics to be evaluated by the model during\n",
              "        training and testing. Each of this can be a string (name of a\n",
              "        built-in function), function or a `keras.metrics.Metric`\n",
              "        instance. See `keras.metrics`. Typically you will use\n",
              "        `metrics=[&#x27;accuracy&#x27;]`. A function is any callable with the\n",
              "        signature `result = fn(y_true, _pred)`. To specify different\n",
              "        metrics for different outputs of a multi-output model, you could\n",
              "        also pass a dictionary, such as\n",
              "        `metrics={&#x27;a&#x27;:&#x27;accuracy&#x27;, &#x27;b&#x27;:[&#x27;accuracy&#x27;, &#x27;mse&#x27;]}`.\n",
              "        You can also pass a list to specify a metric or a list of\n",
              "        metrics for each output, such as\n",
              "        `metrics=[[&#x27;accuracy&#x27;], [&#x27;accuracy&#x27;, &#x27;mse&#x27;]]`\n",
              "        or `metrics=[&#x27;accuracy&#x27;, [&#x27;accuracy&#x27;, &#x27;mse&#x27;]]`. When you pass\n",
              "        the strings &#x27;accuracy&#x27; or &#x27;acc&#x27;, we convert this to one of\n",
              "        `keras.metrics.BinaryAccuracy`,\n",
              "        `keras.metrics.CategoricalAccuracy`,\n",
              "        `keras.metrics.SparseCategoricalAccuracy` based on the\n",
              "        shapes of the targets and of the model output. A similar\n",
              "        conversion is done for the strings `&quot;crossentropy&quot;`\n",
              "        and `&quot;ce&quot;` as well.\n",
              "        The metrics passed here are evaluated without sample weighting;\n",
              "        if you would like sample weighting to apply, you can specify\n",
              "        your metrics via the `weighted_metrics` argument instead.\n",
              "    weighted_metrics: List of metrics to be evaluated and weighted by\n",
              "        `sample_weight` or `class_weight` during training and testing.\n",
              "    run_eagerly: Bool. If `True`, this model&#x27;s forward pass\n",
              "         will never be compiled. It is recommended to leave this\n",
              "         as `False` when training (for best performance),\n",
              "         and to set it to `True` when debugging.\n",
              "    steps_per_execution: Int. The number of batches to run\n",
              "        during each a single compiled function call. Running multiple\n",
              "        batches inside a single compiled function call can\n",
              "        greatly improve performance on TPUs or small models with a large\n",
              "        Python overhead. At most, one full epoch will be run each\n",
              "        execution. If a number larger than the size of the epoch is\n",
              "        passed, the execution will be truncated to the size of the\n",
              "        epoch. Note that if `steps_per_execution` is set to `N`,\n",
              "        `Callback.on_batch_begin` and `Callback.on_batch_end` methods\n",
              "        will only be called every `N` batches (i.e. before/after\n",
              "        each compiled function execution).\n",
              "        Not supported with the PyTorch backend.\n",
              "    jit_compile: Bool or `&quot;auto&quot;`. Whether to use XLA compilation when\n",
              "        compiling a model. For `jax` and `tensorflow` backends,\n",
              "        `jit_compile=&quot;auto&quot;` enables XLA compilation if the model\n",
              "        supports it, and disabled otherwise.\n",
              "        For `torch` backend, `&quot;auto&quot;` will default to eager\n",
              "        execution and `jit_compile=True` will run with `torch.compile`\n",
              "        with the `&quot;inductor&quot;` backend.\n",
              "    auto_scale_loss: Bool. If `True` and the model dtype policy is\n",
              "        `&quot;mixed_float16&quot;`, the passed optimizer will be automatically\n",
              "        wrapped in a `LossScaleOptimizer`, which will dynamically\n",
              "        scale the loss to prevent underflow.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 39);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8eGUQ6DGiv9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "891c4433"
      },
      "source": [
        "# Task\n",
        "The task is to demonstrate various advanced regression techniques, introduce fundamental classification models, and explain model optimization with hyperparameter tuning to improve predictive performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "710732af"
      },
      "source": [
        "## Regression Techniques\n",
        "\n",
        "### Subtask:\n",
        "Elaborate on different regression techniques beyond linear and polynomial regression, such as decision tree regression, support vector regression, or ensemble methods like random forest regression, and demonstrate their implementation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc73f0bc"
      },
      "source": [
        "**Reasoning**:\n",
        "To demonstrate Decision Tree Regression, I need to import the required libraries, split the data into training and testing sets, initialize and train the model, make predictions, and evaluate its performance using Mean Squared Error, as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Keras specific\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "df = pd.read_csv(\"NBD.csv\")\n",
        "x=df.drop('diabetes',axis=1)\n",
        "y=df['diabetes']\n",
        "model = Sequential()\n",
        "model.add(Dense(500, activation='relu', input_dim=2))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x,y, epochs=100)\n",
        "X_marks=[[45,63]]\n",
        "print(model.predict(X_marks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TIfHlRSwqJj7",
        "outputId": "1703ab7f-6e38-46a2-bbc9-136afcb4f89d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.6148 - loss: 0.8799\n",
            "Epoch 2/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7065 - loss: 0.5276\n",
            "Epoch 3/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7104 - loss: 0.5327\n",
            "Epoch 4/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7731 - loss: 0.4539\n",
            "Epoch 5/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7623 - loss: 0.4789\n",
            "Epoch 6/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7591 - loss: 0.5093\n",
            "Epoch 7/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7460 - loss: 0.4979\n",
            "Epoch 8/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7112 - loss: 0.5223\n",
            "Epoch 9/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7271 - loss: 0.4884\n",
            "Epoch 10/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7588 - loss: 0.4668\n",
            "Epoch 11/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7705 - loss: 0.4451\n",
            "Epoch 12/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6895 - loss: 0.5465\n",
            "Epoch 13/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7830 - loss: 0.4533\n",
            "Epoch 14/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7880 - loss: 0.4328\n",
            "Epoch 15/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7732 - loss: 0.4670\n",
            "Epoch 16/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7677 - loss: 0.4666\n",
            "Epoch 17/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7496 - loss: 0.4687\n",
            "Epoch 18/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7825 - loss: 0.4381\n",
            "Epoch 19/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7975 - loss: 0.4356\n",
            "Epoch 20/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7972 - loss: 0.4149\n",
            "Epoch 21/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7790 - loss: 0.4694\n",
            "Epoch 22/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7744 - loss: 0.4758\n",
            "Epoch 23/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7723 - loss: 0.4439\n",
            "Epoch 24/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7909 - loss: 0.4539\n",
            "Epoch 25/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7640 - loss: 0.4498\n",
            "Epoch 26/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7931 - loss: 0.4432\n",
            "Epoch 27/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7764 - loss: 0.4652\n",
            "Epoch 28/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7765 - loss: 0.4463\n",
            "Epoch 29/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7774 - loss: 0.4499\n",
            "Epoch 30/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7841 - loss: 0.4424\n",
            "Epoch 31/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7969 - loss: 0.4109\n",
            "Epoch 32/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7969 - loss: 0.4364\n",
            "Epoch 33/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7795 - loss: 0.4546\n",
            "Epoch 34/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7822 - loss: 0.4313\n",
            "Epoch 35/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.4017\n",
            "Epoch 36/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7758 - loss: 0.4594\n",
            "Epoch 37/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7980 - loss: 0.4316\n",
            "Epoch 38/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7856 - loss: 0.4252\n",
            "Epoch 39/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8055 - loss: 0.4182\n",
            "Epoch 40/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8030 - loss: 0.3986\n",
            "Epoch 41/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7526 - loss: 0.4922\n",
            "Epoch 42/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7897 - loss: 0.4361\n",
            "Epoch 43/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8118 - loss: 0.4024\n",
            "Epoch 44/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7726 - loss: 0.4567\n",
            "Epoch 45/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7948 - loss: 0.4046\n",
            "Epoch 46/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7804 - loss: 0.4293\n",
            "Epoch 47/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7977 - loss: 0.4128\n",
            "Epoch 48/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8112 - loss: 0.3993\n",
            "Epoch 49/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7989 - loss: 0.4009\n",
            "Epoch 50/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7831 - loss: 0.4094\n",
            "Epoch 51/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.4197\n",
            "Epoch 52/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7965 - loss: 0.3865\n",
            "Epoch 53/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8092 - loss: 0.3866\n",
            "Epoch 54/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8229 - loss: 0.3893\n",
            "Epoch 55/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7959 - loss: 0.4166\n",
            "Epoch 56/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8263 - loss: 0.3976\n",
            "Epoch 57/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.3779\n",
            "Epoch 58/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.3798\n",
            "Epoch 59/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8038 - loss: 0.4025\n",
            "Epoch 60/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8330 - loss: 0.3847\n",
            "Epoch 61/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8090 - loss: 0.3890\n",
            "Epoch 62/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7525 - loss: 0.4948\n",
            "Epoch 63/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7701 - loss: 0.4612\n",
            "Epoch 64/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7936 - loss: 0.4063\n",
            "Epoch 65/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7959 - loss: 0.4161\n",
            "Epoch 66/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8226 - loss: 0.3756\n",
            "Epoch 67/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8159 - loss: 0.3588\n",
            "Epoch 68/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7880 - loss: 0.4336\n",
            "Epoch 69/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8148 - loss: 0.3969\n",
            "Epoch 70/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8191 - loss: 0.3727\n",
            "Epoch 71/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.3754\n",
            "Epoch 72/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8323 - loss: 0.3769\n",
            "Epoch 73/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8522 - loss: 0.3312\n",
            "Epoch 74/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8420 - loss: 0.3603\n",
            "Epoch 75/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8104 - loss: 0.3948\n",
            "Epoch 76/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8233 - loss: 0.4033\n",
            "Epoch 77/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3469\n",
            "Epoch 78/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8602 - loss: 0.3387\n",
            "Epoch 79/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8460 - loss: 0.3465\n",
            "Epoch 80/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8903 - loss: 0.3007\n",
            "Epoch 81/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8841 - loss: 0.2975\n",
            "Epoch 82/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8382 - loss: 0.3641\n",
            "Epoch 83/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8595 - loss: 0.3569\n",
            "Epoch 84/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8517 - loss: 0.3205\n",
            "Epoch 85/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8688 - loss: 0.3221\n",
            "Epoch 86/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8740 - loss: 0.3025\n",
            "Epoch 87/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8818 - loss: 0.2762\n",
            "Epoch 88/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8655 - loss: 0.3128\n",
            "Epoch 89/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.3481\n",
            "Epoch 90/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8707 - loss: 0.3141\n",
            "Epoch 91/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8547 - loss: 0.3045\n",
            "Epoch 92/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8756 - loss: 0.3199\n",
            "Epoch 93/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8290 - loss: 0.3361\n",
            "Epoch 94/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8523 - loss: 0.3253\n",
            "Epoch 95/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8586 - loss: 0.3094\n",
            "Epoch 96/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8813 - loss: 0.3008\n",
            "Epoch 97/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8890 - loss: 0.2731\n",
            "Epoch 98/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8929 - loss: 0.2593\n",
            "Epoch 99/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8912 - loss: 0.2578\n",
            "Epoch 100/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8422 - loss: 0.3387\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized data type: x=[[45, 63]] (of type <class 'list'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1227870164.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mX_marks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m63\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_marks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/__init__.py\u001b[0m in \u001b[0;36mget_data_adapter\u001b[0;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unrecognized data type: x={x} (of type {type(x)})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized data type: x=[[45, 63]] (of type <class 'list'>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KDdAnegyqJwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a90a25e3"
      },
      "source": [
        "# Task\n",
        "Convert the prediction input `X_marks` to a NumPy array before calling `model.predict()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfdc21af"
      },
      "source": [
        "## Fix prediction input data type\n",
        "\n",
        "### Subtask:\n",
        "Convert the input `X_marks` to a NumPy array using `np.array()` before passing it to `model.predict()`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9775fb5"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The prediction input `X_marks` needs to be converted to a NumPy array to be compatible with `model.predict()`.\n",
        "*   The specific method to perform this conversion is `np.array()`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Ensure data types of inputs always match the expected format for machine learning models to prevent errors and ensure correct predictions.\n"
      ]
    }
  ]
}